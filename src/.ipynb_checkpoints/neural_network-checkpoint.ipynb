{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando bibliotecas necessárias no projeto\n",
    "from sklearn import svm\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "from keras import regularizers, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.python.client import device_lib\n",
    "from sklearn.svm import SVC\n",
    "from keras import utils as np_utils\n",
    "from keras import backend\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from re import search\n",
    "import numpy as np\n",
    "from subprocess import getoutput as gop\n",
    "import glob\n",
    "import pandas as pd\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando conjuntos de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identificando pastas\n",
    "folders = {\n",
    "    'small': 'dataset/small',\n",
    "    'large_train': 'dataset/large_train',\n",
    "    'large_test': 'dataset/large_test',\n",
    "}\n",
    "\n",
    "def load_data(dataset):\n",
    "    ch_names = []\n",
    "    create_ch_name = False\n",
    "    \n",
    "    data_dir = gop('ls {}'.format(folders[dataset])).split('\\n')\n",
    "    # 1ª dimensão dos dados contendo os sujeitos\n",
    "    subjects = list()\n",
    "    subjects_alc = list()\n",
    "    subjects_ctrl = list()\n",
    "    \n",
    "    for types in data_dir:\n",
    "        files = gop('ls {}/{}'.format(folders[dataset], types)).split('\\n')\n",
    "        # 2ª dimensão dos dados contendo as sessões (trials)\n",
    "        trials = list()\n",
    "        is_alc = True\n",
    "        \n",
    "        for f in files:\n",
    "            arquivo = open('{}/{}/{}'.format(folders[dataset], types, f))\n",
    "            text = arquivo.readlines()\n",
    "            \n",
    "            alc = search('co2a', text[0])\n",
    "            ctrl = search('co2c', text[0])\n",
    "            \n",
    "            if ctrl:\n",
    "                is_alc = False\n",
    "            # 3ª dimensão dos dados contendo os canais (eletrodos)\n",
    "            chs = list()\n",
    "            # 4ª dimensão dos dados contendo os valores em milivolts\n",
    "            values = list()\n",
    "            for line in text:\n",
    "                t = search('(?P<ch_name>\\w{1,3}) chan \\d{1,2}', line)\n",
    "                p = search('^\\d{1,3}\\ \\w{1,3}\\ \\d{1,3}\\ (?P<value>.+$)', line)\n",
    "                                    \n",
    "                if p:\n",
    "                    values.append(float(p.group('value')))\n",
    "                # mudou para outro eletrodo\n",
    "                elif t:\n",
    "                    if values:\n",
    "                        chs.append(values)\n",
    "                        values = list()\n",
    "                    if not create_ch_name:\n",
    "                        ch_names.append(t.group('ch_name').lower())\n",
    "            \n",
    "            create_ch_name = True\n",
    "            chs.append(values)\n",
    "            trials.append(chs)\n",
    "            arquivo.close()\n",
    "            \n",
    "        if is_alc:\n",
    "            subjects_alc.append(trials)\n",
    "            md_alc = np.average(trials, axis=0)\n",
    "        else:\n",
    "            subjects_ctrl.append(trials)\n",
    "            md_ctrl = np.average(trials, axis=0)\n",
    "            \n",
    "    data_alc = np.array(subjects_alc)\n",
    "    data_ctrl = np.array(subjects_ctrl)\n",
    "    \n",
    "#     data.tofile('./dataset_csv/small_data.csv', sep=',', newline='')   \n",
    "    return data_alc, md_alc, data_ctrl, md_ctrl, ch_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_alc, md_alc, data_ctrl, md_ctrl, ch_names = load_data('large_train')\n",
    "data_alc_test, md_alc_test, data_ctrl_test, md_ctrl_test, ch_names_test = load_data('large_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treino\n",
    "\n",
    "y_md_alc = []\n",
    "count = 0\n",
    "for i in range(len(md_alc)):\n",
    "    y_md_alc.insert(count, True)\n",
    "    count += 1\n",
    "\n",
    "y_md_ctrl = []\n",
    "count = 0\n",
    "for i in range(len(md_ctrl)):\n",
    "    y_md_ctrl.insert(count, False)\n",
    "    count += 1\n",
    "\n",
    "md_total = np.concatenate((md_alc, md_ctrl))\n",
    "y_md_total = np.concatenate((y_md_alc, y_md_ctrl))\n",
    "\n",
    "#Teste\n",
    "\n",
    "y_md_alc_test = []\n",
    "count = 0\n",
    "for i in range(len(md_alc_test)):\n",
    "    y_md_alc_test.insert(count, True)\n",
    "    count += 1\n",
    "\n",
    "y_md_ctrl_test = []\n",
    "count = 0\n",
    "for i in range(len(md_ctrl_test)):\n",
    "    y_md_ctrl_test.insert(count, False)\n",
    "    count += 1\n",
    "    \n",
    "md_total_test = np.concatenate((md_alc_test, md_ctrl_test))\n",
    "y_md_total_test = np.concatenate((y_md_alc_test, y_md_ctrl_test))\n",
    "\n",
    "\n",
    "md_array = []\n",
    "md_total_com_y = []\n",
    "count = 0\n",
    "count_md = 0\n",
    "i = 0\n",
    "for item in md_total:\n",
    "    for subitem in item:\n",
    "        md_total_com_y.insert(count, subitem)\n",
    "        count += 1\n",
    "    md_total_com_y.insert(count, y_md_total[i])\n",
    "    count = 0\n",
    "    md_array.insert(count_md, md_total_com_y)\n",
    "    md_total_com_y = []\n",
    "    count_md += 1\n",
    "    i += 1\n",
    "\n",
    "    \n",
    "test_array = []\n",
    "test_total_com_y = []\n",
    "count = 0\n",
    "count_test = 0\n",
    "i = 0\n",
    "for item in md_total_test:\n",
    "    for subitem in item:\n",
    "        test_total_com_y.insert(count, subitem)\n",
    "        count += 1\n",
    "    test_total_com_y.insert(count, y_md_total_test[i])\n",
    "    count = 0\n",
    "    test_array.insert(count_test, test_total_com_y)\n",
    "    test_total_com_y = []\n",
    "    count_test += 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257\n",
      "257\n",
      "[2.5898999999999996, 2.296933333333333, 1.8574333333333333, 1.3529000000000002, 0.8483333333333334, 0.6693333333333334, 0.4252666666666665, 0.22990000000000013, 0.09973333333333327, 0.22986666666666628, 0.4252000000000001, 0.8483999999999999, 1.2064999999999997, 1.3040000000000005, 0.9785666666666664, 0.2624333333333331, -0.42116666666666663, -0.7466666666666668, -0.5187999999999998, -0.03049999999999954, 0.6041333333333333, 0.9135000000000001, 0.6530000000000004, -0.046833333333333546, -0.876866666666667, -1.5442, -1.8370999999999997, -1.5930333333333324, -1.186133333333333, -0.8606333333333336, -0.8116999999999999, -0.9094333333333334, -0.9419666666666673, -0.4047999999999997, 0.3276, 1.141433333333333, 1.353, 0.9134999999999998, 0.1159333333333331, -0.3398000000000003, -0.27463333333333323, 0.21369999999999983, 0.7018, 0.7506999999999999, 0.5879666666666666, 0.49019999999999997, 0.9461333333333333, 1.6622, 2.1504666666666665, 1.971466666666667, 1.2877333333333334, 0.5391666666666666, 0.03450000000000024, -0.1770666666666666, -0.4537000000000001, -0.9420333333333333, -1.4953666666666665, -1.6093666666666668, -1.2023333333333333, -0.4048333333333332, 0.3112333333333334, 0.6856333333333332, 0.9296666666666665, 1.2065000000000003, 1.792433333333333, 2.313233333333334, 2.557466666666666, 2.4108666666666676, 2.085433333333334, 1.9877, 2.183033333333334, 2.524733333333333, 2.3783666666666665, 1.6295666666666668, 0.4090333333333332, -0.6490000000000001, -1.023366666666667, -0.7630333333333336, -0.22579999999999992, -0.06306666666666662, -0.3885666666666665, -1.1047333333333333, -1.9022000000000001, -2.260333333333334, -2.3091666666666666, -2.195266666666667, -2.2928666666666664, -2.6673666666666658, -2.976433333333334, -3.3019000000000007, -3.578733333333333, -3.741566666666666, -3.774, -3.432233333333334, -2.9113666666666673, -2.3091999999999997, -1.837166666666666, -1.7069333333333332, -1.951066666666667, -2.390433333333333, -2.748566666666666, -2.9276666666666666, -2.7812, -2.2603999999999997, -1.3976666666666668, -0.535, -0.09559999999999982, -0.48623333333333346, -1.4628333333333332, -2.5371333333333337, -3.074266666666666, -2.6347, -1.5604, -0.6490333333333335, -0.25836666666666663, -0.7303666666666667, -1.4465999999999999, -2.0812666666666666, -2.3417000000000003, -2.1952000000000007, -1.7558, -1.2186666666666666, -0.7791666666666665, -0.6001666666666668, -0.9582666666666667, -1.8208999999999995, -2.7486333333333346, -3.4159666666666664, -3.5786666666666664, -3.3670999999999998, -3.302, -3.497466666666666, -4.083300000000002, -4.620333333333334, -4.815766666666666, -4.734299999999999, -4.6854000000000005, -4.832033333333333, -5.1087333333333325, -5.482933333333333, -5.483066666666667, -5.1575, -4.571533333333334, -4.262366666666667, -4.2624, -4.587799999999999, -4.897066666666666, -5.141233333333333, -5.320266666666667, -5.434100000000001, -5.483033333333333, -5.401533333333334, -5.011, -4.473833333333333, -4.0668999999999995, -3.9205, -4.148366666666667, -4.587733333333333, -4.636533333333333, -4.1972, -3.6438, -3.2694666666666663, -3.448533333333333, -4.067066666666666, -4.457599999999999, -4.343566666666666, -3.8390333333333335, -3.155533333333333, -2.699800000000001, -2.569633333333334, -2.3742666666666667, -2.048766666666667, -1.3652000000000006, -0.7629333333333336, -0.5025333333333332, -0.4536999999999997, -0.551433333333333, -0.5188, -0.24206666666666668, 0.0020000000000000165, 0.2300000000000001, 0.32749999999999985, 0.13219999999999996, -0.07929999999999979, -0.38870000000000016, -0.6164333333333336, -0.6815, -0.5839666666666667, -0.4049333333333334, -0.3235666666666666, -0.5351, -0.7466999999999998, -0.8280333333333334, -0.5677000000000001, 0.13219999999999985, 0.8483333333333334, 1.1576000000000002, 0.9134333333333337, 0.1484666666666668, -0.6001666666666667, -0.9744666666666665, -0.8117666666666666, -0.32349999999999995, 0.1809999999999998, 0.1647, -0.3722666666666666, -1.2023000000000001, -2.0975333333333332, -2.651033333333333, -2.6835666666666667, -2.2440333333333333, -1.6093000000000002, -1.4465333333333337, -1.5605, -1.9999000000000005, -2.3742666666666663, -2.5044, -2.3417333333333334, -2.065033333333333, -1.951033333333334, -2.0649666666666664, -2.3905666666666665, -2.699799999999999, -2.8137666666666665, -2.7974333333333337, -2.3905333333333325, -1.5928666666666667, -0.9256666666666665, -0.45363333333333306, -0.5676666666666673, -1.3000999999999996, -2.0324000000000004, -2.357966666666667, -2.1137666666666672, -1.4303, -1.0884666666666667, -1.2023666666666666, -1.7720333333333338, -2.309200000000001, -2.374233333333333, -1.9347999999999996, -1.2186333333333332, -0.7954999999999995, -0.6979, -0.9745, -1.0070666666666668, -0.7465999999999997, -0.2257333333333333, 0.06713333333333343, -0.38853333333333306, -1.4302333333333332, -2.5858333333333334, -3.1230666666666664, -2.764866666666667, -1.6744666666666663, -0.7792666666666667, True]\n",
      "False\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(md_array)\n",
    "random.shuffle(test_array)\n",
    "print(len(md_array[0]))\n",
    "print(len(test_array[0]))\n",
    "print(md_array[0])\n",
    "index = 0\n",
    "y_train = []\n",
    "for i in range(len(md_array)):\n",
    "    result = md_array[i][255] #Vetor de resultados\n",
    "    y_train.insert(index, result)\n",
    "    index += 1\n",
    "    \n",
    "print(md_array[40][256])\n",
    "print(len(y_train))\n",
    "\n",
    "for i in range(len(md_array)):\n",
    "    del(md_array[i][256])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.41596667  0.651       0.19533333  0.2767      0.5859      0.79753333\n",
      "  0.6998      0.40693333  0.2115      0.22793333  0.40686667  0.5046\n",
      "  0.48826667  0.30926667  0.2929      0.30916667  0.3093      0.39053333\n",
      "  0.3093      0.09766667 -0.04883333 -0.13023333 -0.2116     -0.4232\n",
      " -0.61853333 -0.97666667 -1.23703333 -1.46486667 -1.709      -1.82283333\n",
      " -1.7741     -1.46493333 -0.84633333 -0.1628      0.47213333  1.10676667\n",
      "  1.7252      2.44143333  3.0598      3.48303333  3.64583333  3.64593333\n",
      "  3.7922      4.08526667  4.63873333  4.94783333  5.06183333  4.8665\n",
      "  4.4434      3.92256667  3.33663333  2.58783333  1.72526667  0.83006667\n",
      "  0.08133333 -0.40693333 -0.68363333 -0.74866667 -0.73236667 -0.74863333\n",
      " -0.6185     -0.50456667 -0.24413333  0.09773333  0.63473333  1.3347\n",
      "  2.002       2.55533333  2.7182      2.767       2.76693333  2.86466667\n",
      "  2.8809      2.767       2.39256667  2.13216667  2.0833      2.11596667\n",
      "  2.24613333  2.18096667  1.69263333  1.0254      0.27673333 -0.45573333\n",
      " -1.12296667 -1.7253     -2.32743333 -2.7995     -2.97853333 -2.84826667\n",
      " -2.5716     -2.34376667 -2.29493333 -2.14846667 -1.87176667 -1.44866667\n",
      " -1.15556667 -1.00916667 -0.9928     -1.05786667 -0.99286667 -0.73243333\n",
      " -0.63473333 -0.65106667 -0.86273333 -1.09046667 -1.23696667 -1.17186667\n",
      " -1.15566667 -1.20443333 -1.15553333 -1.0742     -1.07423333 -1.20443333\n",
      " -1.72526667 -2.45766667 -3.32026667 -3.72723333 -3.88996667 -3.67843333\n",
      " -3.48303333 -3.64586667 -3.95513333 -4.32946667 -4.57353333 -4.32946667\n",
      " -4.1992     -4.10153333 -4.4433     -5.11073333 -5.957      -6.59173333\n",
      " -7.03133333 -7.01503333 -6.8522     -6.73823333 -6.7707     -6.93356667\n",
      " -7.1777     -7.25916667 -7.34043333 -7.3242     -7.34056667 -7.37303333\n",
      " -7.3732     -7.12893333 -6.7708     -6.39646667 -6.11976667 -6.1034\n",
      " -6.28253333 -6.39643333 -6.31513333 -6.0709     -5.66396667 -5.45253333\n",
      " -5.43616667 -5.45253333 -5.46873333 -5.30596667 -5.30603333 -5.306\n",
      " -5.66403333 -5.94083333 -6.0221     -5.8757     -5.61516667 -5.59896667\n",
      " -5.7292     -5.92446667 -5.8106     -5.3874     -4.72003333 -4.08526667\n",
      " -3.75973333 -3.6458     -3.56443333 -3.54816667 -3.46676667 -3.40163333\n",
      " -3.4505     -3.53183333 -3.4668     -3.46683333 -3.4831     -3.49936667\n",
      " -3.59696667 -3.58066667 -3.48303333 -3.2715     -3.07626667 -2.9786\n",
      " -3.12506667 -3.14133333 -3.125      -2.8645     -2.5716     -2.31116667\n",
      " -2.14836667 -2.06706667 -1.9694     -1.823      -1.43223333 -1.07416667\n",
      " -0.7487     -0.48833333 -0.2117      0.04873333  0.40693333  0.8301\n",
      "  1.10673333  1.31823333  1.44853333  1.6764      2.09976667  2.78323333\n",
      "  3.54816667  4.28063333  4.89906667  5.2084      5.5176      5.7617\n",
      "  6.00586667  6.2337      6.41276667  6.33146667  6.24996667  6.05463333\n",
      "  6.05476667  6.15233333  6.24996667  6.41286667  6.3314      6.1362\n",
      "  5.8756      5.56636667  5.28976667  5.11066667  4.88283333  4.62236667\n",
      "  4.37826667  4.0689      3.9714      3.85746667  3.9063      3.88993333\n",
      "  3.776       3.53193333  3.2715      2.99486667  2.92973333  2.94586667\n",
      "  2.99483333  2.91343333  2.88086667  2.9459    ]\n",
      "256\n",
      "256\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input arrays should have the same number of samples as target arrays. Found 128 input samples and 256 target samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-d80c8e9af0e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmd_total\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_md_total\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mloss_and_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmd_total_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_md_total\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    802\u001b[0m             ]\n\u001b[0;32m    803\u001b[0m             \u001b[1;31m# Check that all arrays have the same length.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 804\u001b[1;33m             \u001b[0mcheck_array_length_consistency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    805\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m                 \u001b[1;31m# Additional checks to avoid users mistakenly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mcheck_array_length_consistency\u001b[1;34m(inputs, targets, weights)\u001b[0m\n\u001b[0;32m    235\u001b[0m                          \u001b[1;34m'the same number of samples as target arrays. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m                          \u001b[1;34m'Found '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' input samples '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m                          'and ' + str(list(set_y)[0]) + ' target samples.')\n\u001b[0m\u001b[0;32m    238\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset_w\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m         raise ValueError('All sample_weight arrays should have '\n",
      "\u001b[1;31mValueError\u001b[0m: Input arrays should have the same number of samples as target arrays. Found 128 input samples and 256 target samples."
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "num_input = md_total.shape[1]\n",
    "\n",
    "print(md_total[0])\n",
    "print(y_md_total.size)\n",
    "print(num_input)\n",
    "\n",
    "model.add(Dense(units=100, activation='relu', input_dim=num_input))\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(md_total, y_md_total, validation_split=0.30, epochs=50, batch_size=50, verbose=1)\n",
    "\n",
    "loss_and_metrics = model.evaluate(md_total_test, y_md_total, batch_size=50)\n",
    "print(\"\\n Taxa de acerto: %.2f%%\" % (loss_and_metrics[1]*100))\n",
    " \n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Função de Custo: %.2f%%\" % (loss_and_metrics[0]))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
