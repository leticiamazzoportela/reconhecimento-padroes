{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#importando bibliotecas necessárias no projeto\n",
    "from sklearn import svm\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "from keras import regularizers, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.python.client import device_lib\n",
    "from sklearn.svm import SVC\n",
    "from keras import utils as np_utils\n",
    "from keras import backend\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando conjuntos de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import search\n",
    "import numpy as np\n",
    "from subprocess import getoutput as gop\n",
    "import glob\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# identificando pastas\n",
    "folders = {\n",
    "    'large_train': 'dataset/large_train',\n",
    "    'large_test': 'dataset/large_test',\n",
    "}\n",
    "\n",
    "def load_data(dataset):\n",
    "    ch_names = []\n",
    "    create_ch_name = False\n",
    "    \n",
    "    data_dir = gop('ls {}'.format(folders[dataset])).split('\\n')\n",
    "    # 1ª dimensão dos dados contendo os sujeitos\n",
    "    subjects = list()\n",
    "    subjects_alc = list()\n",
    "    subjects_ctrl = list()\n",
    "    \n",
    "    for types in data_dir:\n",
    "        files = gop('ls {}/{}'.format(folders[dataset], types)).split('\\n')\n",
    "        # 2ª dimensão dos dados contendo as sessões (trials)\n",
    "        trials = list()\n",
    "        is_alc = True\n",
    "        \n",
    "        for f in files:\n",
    "            arquivo = open('{}/{}/{}'.format(folders[dataset], types, f))\n",
    "            text = arquivo.readlines()\n",
    "            \n",
    "            alc = search('co2a', text[0])\n",
    "            ctrl = search('co2c', text[0])\n",
    "            \n",
    "            if ctrl:\n",
    "                is_alc = False\n",
    "            # 3ª dimensão dos dados contendo os canais (eletrodos)\n",
    "            chs = list()\n",
    "            # 4ª dimensão dos dados contendo os valores em milivolts\n",
    "            values = list()\n",
    "            for line in text:\n",
    "                t = search('(?P<ch_name>\\w{1,3}) chan \\d{1,2}', line)\n",
    "                p = search('^\\d{1,3}\\ \\w{1,3}\\ \\d{1,3}\\ (?P<value>.+$)', line)\n",
    "                                    \n",
    "                if p:\n",
    "                    values.append(float(p.group('value')))\n",
    "                # mudou para outro eletrodo\n",
    "                elif t:\n",
    "                    if values:\n",
    "                        chs.append(values)\n",
    "                        values = list()\n",
    "                    if not create_ch_name:\n",
    "                        ch_names.append(t.group('ch_name').lower())\n",
    "            \n",
    "            create_ch_name = True\n",
    "            chs.append(values)\n",
    "            trials.append(chs)\n",
    "            arquivo.close()\n",
    "            \n",
    "        if is_alc:\n",
    "            subjects_alc.append(trials)\n",
    "            md_alc = np.average(trials, axis=0)\n",
    "        else:\n",
    "            subjects_ctrl.append(trials)\n",
    "            md_ctrl = np.average(trials, axis=0)\n",
    "            \n",
    "    data_alc = np.array(subjects_alc)\n",
    "    data_ctrl = np.array(subjects_ctrl)\n",
    "    \n",
    "#     data.tofile('./dataset_csv/small_data.csv', sep=',', newline='')\n",
    "        \n",
    "    return data_alc, md_alc, data_ctrl, md_ctrl, ch_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_train_alc, md_alc_train, lg_train_ctrl, md_ctrl_train, ch_names = load_data('large_train')\n",
    "lg_test_alc, md_alc_test, lg_test_ctrl, md_ctrl_test, ch_names = load_data('large_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=100, activation='relu', input_dim=num_input))\n",
    "model.add(Dense(units=59, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(lg_train_alc, lg_train_ctrl, validation_split=0.30, epochs=50, batch_size=50, verbose=1)\n",
    "\n",
    "loss_and_metrics = model.evaluate(lg_test_alc, lg_test_ctrl, batch_size=16)\n",
    "print(\"\\n Taxa de acerto: %.2f%%\" % (loss_and_metrics[1]*100))\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Função de Custo: %.2f%%\" % (loss_and_metrics[0]))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
